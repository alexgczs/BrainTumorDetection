{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocesado de imagenes\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\npath='../input/rsna-miccai-png/train'\n\nimages=[]\npacientes=[]\nlist_directorios=[folder[1] for folder in os.walk(path)]\nfor paciente in list_directorios[0][:10]:\n    fotos_paciente=[folde[2] for folde in os.walk(f'{path}/{paciente}/FLAIR')]\n    if len(fotos_paciente)==0:\n        continue\n    for foto in fotos_paciente[0]:\n        images.append(Image.open(f\"{path}/{paciente}/FLAIR/{foto}\").convert('RGB'))\n        pacientes.append(paciente)\n        \n        \n        \npath='../input/rsna-miccai-png/test'\nimages_t=[]\npacientes_t=[]\nlist_directorios=[folder[1] for folder in os.walk(path)]\nfor paciente in list_directorios[0][:10]:\n    fotos_paciente=[folde[2] for folde in os.walk(f'{path}/{paciente}/FLAIR')]\n    if len(fotos_paciente)==0:\n        continue\n    for foto in fotos_paciente[0]:\n        images_t.append(Image.open(f\"{path}/{paciente}/FLAIR/{foto}\").convert('RGB'))\n        pacientes_t.append(paciente)\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creo un df con el id del paciente y la fotos\n# (cada fila es una foto, un paciente tiene muchas filas por lo tanto)\n\n#TRAIN\nimages_df=pd.DataFrame()\nimages_df['Pacientes']=pacientes\nimages_df['Imagenes']=images\nimages_df\n\n#TEST\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Import labels\nlabels_df=pd.read_csv('../input/train-labelscsv/train_labels.csv')\nlabels_df=labels_df.rename(columns={'BraTS21ID': 'Pacientes'})\nimages_df['Pacientes']=pd.to_numeric(images_df['Pacientes'])\n\n#  Añado las labels con left join\nimages_df=images_df.merge(labels_df,on='Pacientes',how='left')\n# images_df=images_df.drop(columns=['Pacientes','%Blanco']).rename(columns={'MGMT_value':'Label'})\n\n\n#Genero train/test set\n\ntrain_df=images_df.iloc[:29400]\ntest_df=images_df.iloc[29400:]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=test_df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hago los trai/test sets de diferentes tamaños\n\n# Train 882 Test 378\ntrain_small_df=train_df.sample(frac=0.03,random_state=200).reset_index().drop(columns=['index'])\ntest_small_df=test_df.sample(frac=0.03,random_state=200).reset_index().drop(columns=['index'])\n\n# Train 2940 Test 1260\ntrain_medium_df=train_df.sample(frac=0.1,random_state=200).reset_index().drop(columns=['index'])\ntest_medium_df=test_df.sample(frac=0.1,random_state=200).reset_index().drop(columns=['index'])\n\n# Train 8820 Test 2781\ntrain_big_df=train_df.sample(frac=0.3,random_state=200).reset_index().drop(columns=['index'])\ntest_big_df=test_df.sample(frac=0.3,random_state=200).reset_index().drop(columns=['index'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#Creo clase para facilitar la entrada de los datos a dataloaders\nfrom PIL import Image\n\nclass BrainData(torch.utils.data.Dataset):\n    def __init__(self, dataframe, transforms):\n       \n     \n        self.transforms = transforms\n        self.dataframe=dataframe\n        \n\n    def __getitem__(self, idx):\n         \n        #Unnecesary\n        #pacient_id =self.dataframe.loc[[idx], ['Pacientes']]\n        #Get image and category, the two statements that vit is going to use to learn\n        imgs=[x[0] for x in self.dataframe.loc[[idx],['Imagenes']].values][0]\n        #Cuando los labels esten en el df\n        category=int(self.dataframe.loc[[idx],['MGMT_value']].values)\n        if category==0:\n            category=torch.Tensor([0.])\n        else:\n            category=torch.Tensor([1.])\n        \n        if self.transforms is not None:\n            imgs = self.transforms(imgs)\n\n        return imgs, category\n\n    def __len__(self):\n        return len(self.dataframe['MGMT_value'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transforms: Main, the resize to the vit default size. Maybe we can append more???\n\nimport torchvision.transforms as T\nimport random\n\ndef get_transform(train):\n    transform = []\n    transform.append(T.PILToTensor())\n    transform.append(T.ConvertImageDtype(torch.float))\n    transform.append(T.Resize((224,224)))\n \n\n    return T.Compose(transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creation of datasets (one to train, one to test)\n\ntrain_dataset=BrainData(train_df, get_transform(train=True))\ntest_dataset=BrainData(test_df,get_transform(train=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataloaders\n\nimport torch.utils\n\n#data_loaders\ndata_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=16, shuffle=True, num_workers=0)\n\ndata_loader_test = torch.utils.data.DataLoader(\n        test_dataset, batch_size=16, shuffle=False, num_workers=0)\n\ndataloaders={\"train\": data_loader, \"test\": data_loader_test}\n\ndataset_sizes={\"train\": len(train_dataset), \"test\":len(test_dataset)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train model function\n\nimport time\nimport copy\nimport tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n    model.to(device)\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n                scheduler.step()\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            #Tqdm for estimation of time\n            for inputs, labels in tqdm.tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n               \n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n               \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n               #Doesnt matter, only if we have time\n                #running_loss += loss.item() * inputs.size(0)\n              \n                running_corrects += torch.sum(torch.reshape(preds,(1,-1)) == torch.reshape(labels.data,(1,-1)))\n              \n             #Doesnt matter, only if we have time\n            #epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects/ dataset_sizes[phase]\n\n            print(f'{phase} Acc: {epoch_acc:.4f}')\n\n            # Save best model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best test Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define the parameters\nimport torchvision\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#Load VIT (Maybe a big vit model)\nmodel_transf = torchvision.models.vit_b_16(pretrained=True)\n\nfor param in model_transf.parameters():\n    param.requires_grad = False\n\n\n\n\n#Number of classes: 2, positive or negative. Access to the last layer and change output size\nmodel_transf.heads = nn.Linear( model_transf.heads.head.in_features, 1)\n\n#loss function\ncriterion = nn.CrossEntropyLoss()\noptimizer= optim.SGD(model_transf.parameters(), lr=0.001, momentum=0.9)\nlr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Train time!!\n\nprint(device)\nmodel_transf = train_model(model_transf, dataloaders, criterion, optimizer,lr_scheduler, num_epochs=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#With model trained, to predict:\n#Pseudo\n\n# input=imagen\n# output=model_transf(input)\n# _,pred=torch.max(output, 1)\n# return pred\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}